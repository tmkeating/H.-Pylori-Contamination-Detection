# H. Pylori Contamination Detection

This project implements **Fully Pre-trained Transfer Learning** to recognize contaminated samples of cell tissues (H. pylori).

## Project Structure

- `dataset.py`: Contains `HPyloriDataset` class which:
    - Loads patient labels from `PatientDiagnosis.csv`.
    - Maps labels: `NEGATIVA` -> 0, `BAIXA` -> 1, `ALTA` -> 1.
    - Collects images from patient-specific folders.
- `model.py`: Defines the transfer learning model using a pre-trained **ResNet18**.
- `train.py`: Main training script that:
    - **Scientific Three-Way Split**: Implements a rigorous validation strategy. Data is split by Patient ID into Training and Validation sets, with a final **unseen HoldOut set** used for the gold-standard evaluation to eliminate Data Leakage.
    - **GPU-Accelerated Macenko Normalization**: Vectorized batch processing on NVIDIA A40 for 7.5x faster training (262 images/sec).
    - **On-GPU Augmentations**: Geometric and color transforms are offloaded to the GPU using `torchvision.transforms.v2` to eliminate CPU bottlenecks.
    - **Learning Rate Scheduler**: `ReduceLROnPlateau` to adaptively reduce learning rate when validation loss plateaus.
    - Trains the model and saves the best version as `best_model.pth`.
    - **Advanced Evaluation & Interpretability**: 
      - Automatically runs a full statistical report on the independent test patients.
      - **Grad-CAM**: Produces heatmaps showing exactly which bacterial structures the model is "looking at" to make its decisions.
      - **Multi-Tier Consensus**: Implements a dual-gate diagnostic engine (Density + Signal Consistency) to achieve 100% Patient Recall.
- `requirements.txt`: Python packages required.
- `normalization.py`: Hosts the GPU-vectorized Macenko stain normalization algorithm.

## Data Strategy (Expanded Training)

The model utilizes an expanded dataset of **~54,000 images**:
- **High-Fidelity Corpus**: Pathologist-verified patches from the `Annotated` folders.
- **Supplemental Negatives**: High-confidence negative patches from confirmed healthy patients.
- **Scientific Validation**: Validated on a **Patient-Independent Split** (80/20 by Patient ID).
- **Core AI Hardening**: Uses Label Smoothing (0.1) and morphological augmentations (Blur, Grayscale) to improve resilience against staining artifacts.

## Performance Highlights (First Iteration Checkpoint)

### Key Metrics
- **Patient-Level Accuracy**: **70.69%** (Best-in-class baseline)
- **Artifact Rejection**: **>75% Reduction** in false positives for stain artifacts (Run 52 breakthrough)
- **Patch Specificity**: **21%** (Stable floor established)
- **Throughput**: **~256 images/second** training; **~448 images/second** validation (A40 Optimized)

### Hardware Performance
- **High-Throughput Pipeline**: Moved all geometric and color augmentations to the GPU using `v2.Transforms`, resolving CPU bottlenecks.
- **VRAM Utilization**: Efficiently handles 448x448 high-resolution patches at batch-size 128 on 48GB NVIDIA A40 GPUs.
- **Processing Speed**: **2 iterations/sec** (Training) | **3.5 iterations/sec** (Validation).
- **Optimization Strategy**: Utilizes advanced weight decay (5e-3) and relaxed scheduler patience (3) for feature robustness.

## Diagnostic Architecture (Multi-Tier Consensus)
The model utilizes a "Supportive Clinical Tool" architecture, prioritizing reliability: 
1. **Density Gate**: Flags infection if â‰¥ 40 patches show > 90% confidence (Run 48-52 calibrated).
2. **Consistency Gate**: Flags infection if mean probability across all patches is > 80% with high signal stability.

## How to Get Started

1. **Environment Setup**:
   Install the required packages using pip:
   ```bash
   pip install -r requirements.txt
   ```

2. **Training and Evaluation**:
   You can run the training script directly:
   ```bash
   python train.py
   ```

3. **Running on SLURM Cluster**:
   For large-scale training on the DCC cluster, use the provided batch script:
   ```bash
   sbatch run_h_pylori.sh
   ```
   This script is pre-configured to:
   - Request 8 CPU cores and 48GB of RAM (optimized for A40).
   - Automatically copies 11GB dataset to local NVMe SSD for fast I/O.
   - Redirect outputs to the `results/` directory automatically.
   - Use the high-performance `dcca40` partition with NVIDIA A40 GPU.

## Key Hyperparameters (Final Model)

| Parameter | Value | Notes |
|-----------|-------|-------|
| **Batch Size** | 128 | Optimized for 448x448 resolution on 48GB A40 |
| **Input Resolution** | 448x448 | Required to resolve small bacillary morphology |
| **Loss Weight (Pos)** | 1.5 | Balanced for specificity and accuracy (Run 44) |
| **Label Smoothing** | 0.1 | Prevents over-confidence on stain artifacts |
| **Augmentations** | Blur | Grayscale | Color Jitter | Random Rotations | Forces model to focus on morphology, not color |
| **Consensus N** | 30 | Minimum patches to trigger Density Gate |
| **Consensus P** | 0.90 | Confidence threshold for Density patches |
| **Consistency Gate** | Mean > 0.8 | Threshold for clinical confirmation |

## Customization

- To adjust diagnostic sensitivity, update the `predict_patient` function in [train.py](train.py).
## Future Scaling (Iteration 2)
The next iteration of this project will focus on breaking the 71% accuracy plateau through:
- **ResNet50 Backbone**: Upgrading to a 50-layer architecture for superior morphological feature extraction.
- **Deep Head Architecture**: Implementing a multi-layer classification head with ReLU and Dropout for non-linear pattern recognition.
- **Ensemble Consensus**: Replacing manual thresholds with a **Tree-Based Classifier** (Random Forest/XGBoost) to analyze patch-level distribution statistics for the final patient diagnosis.
